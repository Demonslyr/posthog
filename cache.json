[
    {
        "path": "products/llm_observability/frontend/components/FeedbackTag.tsx",
        "summary": "Main Functionality: Displays user feedback within a tag, allowing the feedback to be copied to the clipboard.\nUser-Facing Features:\nUser feedback display\nCopy to clipboard\nFeedback preview\n"
    },
    {
        "path": "products/llm_observability/frontend/LLMObservabilityReloadAction.tsx",
        "summary": "Main Functionality: Provides a button to refresh LLM observability dashboard items and displays the last refresh time.\nUser-Facing Features:\nRefresh button\nLoading indicator\nLast updated timestamp\n"
    },
    {
        "path": "products/llm_observability/frontend/ConversationDisplay/ConversationDisplay.tsx",
        "summary": "Main Functionality: Displays a conversation, including metadata and messages, based on event properties.\nUser-Facing Features:\nConversation display\nMetadata header\nMessage display\nAI model information\nCost and token usage"
    },
    {
        "path": "products/llm_observability/frontend/LLMObservabilityTracesScene.tsx",
        "summary": "Main Functionality: Displays LLM traces in a data table with filtering and navigation to individual trace details.\n\nUser-Facing Features:\nLLM trace table\nFilter test accounts\nDate range selection\nTrace detail navigation\n"
    },
    {
        "path": "products/llm_observability/frontend/ConversationDisplay/ParametersHeader.tsx",
        "summary": "Main Functionality: Displays AI model parameters as tags.\nUser-Facing Features:\nAI model parameters\nParameter display\nTag-based display\n"
    },
    {
        "path": "products/llm_observability/frontend/components/MetricTag.tsx",
        "summary": "Main Functionality: Displays a metric name and value as a tag, allowing the user to copy the metric value to the clipboard.\nUser-Facing Features:\nMetric display\nCopy metric value\nTooltip description\n"
    },
    {
        "path": "products/llm_observability/frontend/ConversationDisplay/MetadataHeader.tsx",
        "summary": "Main Functionality: Displays metadata related to a conversation or LLM interaction, such as latency, token usage, model name, and cost.\n\nUser-Facing Features:\nError status\nLatency display\nToken usage\nModel name\nCost display"
    },
    {
        "path": "products/llm_observability/frontend/components/MetadataTag.tsx",
        "summary": "Main Functionality: Renders a tag with metadata, optionally providing a tooltip or copy-to-clipboard functionality.\nUser-Facing Features:\nMetadata display\nTooltip on hover\nCopy to clipboard\n"
    },
    {
        "path": "products/llm_observability/frontend/LLMInputOutput.tsx",
        "summary": "Main Functionality: Displays input and output sections with headings and optional borders, separated by a divider.\nUser-Facing Features:\nInput display\nOutput display\nCustomizable headings\nOptional borders\n"
    },
    {
        "path": "products/llm_observability/frontend/ConversationDisplay/ConversationMessagesDisplay.tsx",
        "summary": "Main Functionality: Displays LLM conversation messages, including input, output, and tool usage, with options for formatting and viewing.\n\nUser-Facing Features:\nConversation display\nMarkdown toggle\nContent visibility\nCopy to clipboard\nError display\n"
    },
    {
        "path": "products/llm_observability/frontend/LLMObservabilityUsers.tsx",
        "summary": "Main Functionality: Displays a table of users related to LLM observability, including their activity and costs, fetched via a HogQL query.\n\nUser-Facing Features:\n- User data table\n- Person display\n- Filter test accounts\n- Date range filtering\n"
    },
    {
        "path": "products/llm_observability/frontend/llmObservabilityTraceDataLogic.ts",
        "summary": "Main Functionality: Manages and processes LLM trace data, including fetching, filtering, and structuring events into a tree format for visualization.\n\nUser-Facing Features:\nLLM trace visualization\nAI feedback metrics\nEvent filtering\nTrace event tree\n"
    },
    {
        "path": "products/llm_observability/frontend/types.ts",
        "summary": "Main Functionality: Defines TypeScript interfaces for representing messages and tool calls in LLM conversations, supporting OpenAI, Anthropic, and a generic \"Compat\" format.\n\nUser-Facing Features:\nLLM message types\nTool call representation\nOpenAI message format\nAnthropic message format\nCompat message format\n"
    },
    {
        "path": "products/llm_observability/frontend/LLMObservabilityTraceScene.tsx",
        "summary": "Main Functionality: Displays detailed information about LLM traces and events, including metadata, input/output, and a hierarchical tree view of the trace.\n\nUser-Facing Features:\nTrace details view\nLLM event inspection\nTrace tree navigation\nCost & usage metrics"
    },
    {
        "path": "products/llm_observability/frontend/llmObservabilityTraceLogic.ts",
        "summary": "Main Functionality: Manages the state and logic for displaying a specific LLM observability trace, including fetching trace data and managing URL parameters.\n\nUser-Facing Features:\nTrace ID\nEvent ID\nDate Range\nBreadcrumbs\n"
    },
    {
        "path": "products/llm_observability/frontend/llmObservabilityLogic.tsx",
        "summary": "Main Functionality: Manages state and logic for LLM observability features, including data fetching, filtering, and dashboard tile configuration.\n\nUser-Facing Features:\nDate range filtering\nTest accounts filtering\nDashboard visualizations\nGenerations/Traces queries\nCost analysis"
    },
    {
        "path": "products/llm_observability/frontend/LLMObservabilityScene.tsx",
        "summary": "Main Functionality: Provides a user interface for observing and analyzing LLM (Large Language Model) generations, traces, and users, including dashboards, data tables, and filtering capabilities.\n\nUser-Facing Features:\nLLM Observability Dashboard\nLLM Generation Analysis\nLLM Trace Exploration\nLLM User Insights"
    },
    {
        "path": "products/llm_observability/manifest.tsx",
        "summary": "Main Functionality: Defines the manifest for the LLM Observability product, including its scenes, routes, URLs, and other configuration details for the frontend.\n\nUser-Facing Features:\nLLM observability dashboard\nLLM generation tracking\nLLM trace analysis\nLLM user insights\n"
    },
    {
        "path": "products/llm_observability/frontend/utils.ts",
        "summary": "Main Functionality: Provides utility functions for formatting and normalizing data related to LLM observability, including usage, latency, cost, and message content from various LLM providers (OpenAI, Anthropic, Vercel).\n\nUser-Facing Features:\nLLM Usage Formatting\nLLM Latency Formatting\nLLM Cost Formatting\nLLM Message Normalization\nLLM Event Title Formatting\n"
    },
    {
        "path": "products/llm_observability/frontend/components",
        "summary": "Main Functionality: Provides reusable UI components for displaying feedback, metadata, and metrics as tags, with copy-to-clipboard and tooltip functionalities.\nUser-Facing Features:\nFeedback Tags - User feedback display, Copy to clipboard, Feedback preview\nMetadata Tags - Metadata display, Tooltip on hover, Copy to clipboard\nMetric Tags - Metric display, Copy metric value, Tooltip description\n"
    },
    {
        "path": "products/llm_observability/frontend/ConversationDisplay",
        "summary": "Main Functionality: Displays LLM conversations, including messages, metadata, and model parameters.\nUser-Facing Features:\nConversation Display - Conversation display, Message display\nConversation Metadata - Metadata header, Latency display, Token usage, Model name, Cost display, Error status\nAI Model Parameters - AI model parameters, Parameter display, Tag-based display\nMessage Formatting - Markdown toggle, Content visibility, Copy to clipboard, Error display\nAI Model Information - AI model information\nCost and Token Usage - Cost and token usage\n"
    },
    {
        "path": "products/llm_observability/frontend",
        "summary": "Main Functionality: Provides a user interface for observing, analyzing, and managing LLM (Large Language Model) generations, traces, and users, including dashboards, data tables, filtering capabilities, and detailed trace views.\n\nUser-Facing Features:\nLLM Observability Dashboard - LLM Generation Analysis, Dashboard visualizations, Cost analysis, Refresh button, Loading indicator, Last updated timestamp\nLLM Trace Exploration - LLM trace table, Trace detail navigation, Trace details view, LLM event inspection, Trace tree navigation, Cost & usage metrics, LLM trace visualization, AI feedback metrics, Event filtering, Trace event tree\nLLM User Insights - User data table, Person display\nLLM Conversation Display - Conversation Display, Message display, Conversation Metadata, AI Model Parameters, Message Formatting, AI Model Information, Cost and Token Usage\nData Filtering - Filter test accounts, Date range selection, Date range filtering\nData Formatting - LLM Usage Formatting, LLM Latency Formatting, LLM Cost Formatting, LLM Message Normalization, LLM Event Title Formatting\nUI Components - Feedback Tags, Metadata Tags, Metric Tags\n"
    },
    {
        "path": "products/llm_observability",
        "summary": "Main Functionality: Provides a user interface and configuration for observing, analyzing, and managing LLM generations, traces, and users, including dashboards, data tables, filtering capabilities, detailed trace views, and product manifest definition.\nUser-Facing Features:\nLLM Observability - LLM Generation Analysis, Dashboard visualizations, Cost analysis, Refresh button, Loading indicator, Last updated timestamp, LLM observability dashboard, LLM generation tracking, LLM trace analysis, LLM user insights\nLLM Trace Exploration - LLM trace table, Trace detail navigation, Trace details view, LLM event inspection, Trace tree navigation, Cost & usage metrics, LLM trace visualization, AI feedback metrics, Event filtering, Trace event tree\nLLM User Insights - User data table, Person display\nLLM Conversation Display - Conversation Display, Message display, Conversation Metadata, AI Model Parameters, Message Formatting, AI Model Information, Cost and Token Usage\nData Filtering - Filter test accounts, Date range selection, Date range filtering\nData Formatting - LLM Usage Formatting, LLM Latency Formatting, LLM Cost Formatting, LLM Message Normalization, LLM Event Title Formatting\nUI Components - Feedback Tags, Metadata Tags, Metric Tags\n"
    }
]
